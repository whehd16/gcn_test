import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np

class PositionalGCN(nn.Module):
    """
    ê³¡ IDì— ì˜ì¡´í•˜ì§€ ì•Šê³  ìœ„ì¹˜ì /êµ¬ì¡°ì  íŠ¹ì„±ë§Œìœ¼ë¡œ í•™ìŠµí•˜ëŠ” GCN
    """
    def __init__(self, in_features, hidden_features, out_features):
        super(PositionalGCN, self).__init__()
        self.gc1 = nn.Linear(in_features, hidden_features)
        self.gc2 = nn.Linear(hidden_features, hidden_features)
        self.gc3 = nn.Linear(hidden_features, out_features)
        self.dropout = nn.Dropout(0.3)
        
    def forward(self, x, adj):
        # x: [batch_size, num_nodes, features]
        # adj: [batch_size, num_nodes, num_nodes]
        
        # ì²« ë²ˆì§¸ GCN ë ˆì´ì–´
        h1 = torch.relu(self.gc1(torch.bmm(adj, x)))
        h1 = self.dropout(h1)
        
        # ë‘ ë²ˆì§¸ GCN ë ˆì´ì–´
        h2 = torch.relu(self.gc2(torch.bmm(adj, h1)))
        h2 = self.dropout(h2)
        
        # ì¶œë ¥ ë ˆì´ì–´
        out = self.gc3(torch.bmm(adj, h2))
        
        return out

class TimeSeriesPositionalRecommendation(nn.Module):
    """
    ì‹œê³„ì—´ ìœ„ì¹˜ íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸
    """
    def __init__(self, node_features=3, hidden_features=64, time_features=32):
        super(TimeSeriesPositionalRecommendation, self).__init__()
        
        # ê° ì²­í¬ì˜ ê·¸ë˜í”„ íŒ¨í„´ í•™ìŠµ
        self.gcn = PositionalGCN(node_features, hidden_features, hidden_features)
        
        # ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ
        self.lstm = nn.LSTM(hidden_features, time_features, batch_first=True, bidirectional=True)
        
        # ì‹œê³„ì—´ í‘œí˜„ì„ ìœ„í•œ ë ˆì´ì–´
        self.time_encoder = nn.Sequential(
            nn.Linear(time_features * 2, hidden_features),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        
        # ë…¸ë“œë³„ ì¶”ì²œ ì ìˆ˜ ì˜ˆì¸¡
        self.node_scorer = nn.Sequential(
            nn.Linear(hidden_features * 2, hidden_features),  # ì‹œê³„ì—´ + ë…¸ë“œ íŠ¹ì„±
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_features, 1),
            nn.Sigmoid()
        )
        
    def forward(self, chunk_features, chunk_adjs, chunk_sizes, predict_chunk_idx=None):
        batch_size = chunk_features.size(0)
        
        # ê° ì²­í¬ë³„ GCN ì²˜ë¦¬
        chunk_embeddings = []
        all_node_embeddings = []
        
        for i in range(batch_size):
            size = chunk_sizes[i]
            features = chunk_features[i:i+1, :size, :]
            adj = chunk_adjs[i:i+1, :size, :size]
            
            # GCNìœ¼ë¡œ ë…¸ë“œ ì„ë² ë”© ìƒì„±
            node_embeddings = self.gcn(features, adj)  # [1, size, hidden]
            all_node_embeddings.append(node_embeddings)
            
            # ì²­í¬ ì „ì²´ í‘œí˜„
            chunk_repr = torch.mean(node_embeddings, dim=1)  # [1, hidden]
            chunk_embeddings.append(chunk_repr)
        
        # ì‹œê³„ì—´ ì„ë² ë”© ìƒì„±
        time_embeddings = torch.cat(chunk_embeddings, dim=0).unsqueeze(0)  # [1, num_chunks, hidden]
        
        # LSTMìœ¼ë¡œ ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ
        lstm_out, _ = self.lstm(time_embeddings)  # [1, num_chunks, time_features*2]
        
        # ì „ì²´ ì‹œê³„ì—´ í‘œí˜„
        time_repr = self.time_encoder(torch.mean(lstm_out, dim=1))  # [1, hidden]
        
        # íŠ¹ì • ì²­í¬ì˜ ë…¸ë“œë“¤ì— ëŒ€í•œ ì¶”ì²œ ì ìˆ˜ ê³„ì‚°
        if predict_chunk_idx is not None:
            target_nodes = all_node_embeddings[predict_chunk_idx].squeeze(0)  # [size, hidden]
            num_nodes = target_nodes.size(0)
            
            # ì‹œê³„ì—´ í‘œí˜„ì„ ê° ë…¸ë“œì™€ ê²°í•©
            time_repr_expanded = time_repr.expand(num_nodes, -1)  # [size, hidden]
            combined = torch.cat([target_nodes, time_repr_expanded], dim=1)  # [size, hidden*2]
            
            # ê° ë…¸ë“œì˜ ì¶”ì²œ ì ìˆ˜
            node_scores = self.node_scorer(combined).squeeze(1)  # [size]
            return node_scores
        else:
            # í›ˆë ¨ ì‹œì—ëŠ” ì „ì²´ íŒ¨í„´ ì ìˆ˜ë§Œ ë°˜í™˜
            return torch.mean(time_repr)

def preprocess_positional_chunks(chunks):
    """
    ìœ„ì¹˜ ê¸°ë°˜ íŠ¹ì„±ë§Œ ì¶”ì¶œ (ê³¡ ID ì œê±°)
    """
    max_chunk_size = max(len(chunk) for chunk in chunks)
    num_chunks = len(chunks)
    
    # íŠ¹ì§•: [ê±°ë¦¬, ìˆœìœ„_ì •ê·œí™”, ê±°ë¦¬_ì •ê·œí™”]ë§Œ ì‚¬ìš© (ê³¡ ID ì œì™¸)
    chunk_features = np.zeros((num_chunks, max_chunk_size, 3))
    chunk_adjs = np.zeros((num_chunks, max_chunk_size, max_chunk_size))
    chunk_sizes = []
    
    for chunk_idx, chunk in enumerate(chunks):
        chunk_size = len(chunk)
        chunk_sizes.append(chunk_size)
        
        # í•´ë‹¹ ì²­í¬ì—ì„œì˜ ê±°ë¦¬ ë²”ìœ„
        distances = [item['dis'] for item in chunk]
        min_dist, max_dist = min(distances), max(distances)
        dist_range = max_dist - min_dist if max_dist > min_dist else 1
        
        for i, song_data in enumerate(chunk):
            # íŠ¹ì§• 1: ì›ë³¸ ê±°ë¦¬
            chunk_features[chunk_idx, i, 0] = song_data['dis']
            
            # íŠ¹ì§• 2: ì²­í¬ ë‚´ ìˆœìœ„ (0~1 ì •ê·œí™”, 0ì´ ìµœìƒìœ„)
            chunk_features[chunk_idx, i, 1] = i / max(chunk_size - 1, 1)
            
            # íŠ¹ì§• 3: ì²­í¬ ë‚´ ê±°ë¦¬ ì •ê·œí™” (0~1)
            normalized_dist = (song_data['dis'] - min_dist) / dist_range
            chunk_features[chunk_idx, i, 2] = normalized_dist
        print(chunks)
        print(chunk_features)
        
        # ì¸ì ‘ í–‰ë ¬: ê±°ë¦¬ì™€ ìˆœìœ„ ìœ ì‚¬ë„ ê¸°ë°˜
        for i in range(chunk_size):
            for j in range(chunk_size):
                if i == j:
                    chunk_adjs[chunk_idx, i, j] = 1.0
                else:
                    # ê±°ë¦¬ ìœ ì‚¬ë„
                    dist_sim = np.exp(-abs(chunk[i]['dis'] - chunk[j]['dis']) * 5)
                    # ìˆœìœ„ ìœ ì‚¬ë„
                    rank_sim = np.exp(-abs(i - j) * 0.5)
                    # ê²°í•© ìœ ì‚¬ë„
                    chunk_adjs[chunk_idx, i, j] = (dist_sim + rank_sim) / 2
    
    return chunk_features, chunk_adjs, chunk_sizes

# ì‹¤í—˜ ë°ì´í„°: ê³¡ IDëŠ” ë‹¨ìˆœ placeholder
chunks = [
    # ì‹œì  1: íƒ€ê²Ÿì´ ìµœìƒìœ„ (IDëŠ” ì˜ë¯¸ì—†ìŒ)
    [{'tid': 'song_X', 'dis': 0.1}, {'tid': 'song_Y', 'dis': 0.2}, {'tid': 'song_Z', 'dis': 0.25}],
    
    # ì‹œì  2: íƒ€ê²Ÿì´ ì—¬ì „íˆ ìƒìœ„ê¶Œ
    [{'tid': 'song_A', 'dis': 0.12}, {'tid': 'song_X', 'dis': 0.15}, {'tid': 'song_B', 'dis': 0.22}],
    
    # ì‹œì  3: íƒ€ê²Ÿì´ ì¤‘ìœ„ê¶Œìœ¼ë¡œ
    [{'tid': 'song_C', 'dis': 0.11}, {'tid': 'song_X', 'dis': 0.28}, {'tid': 'song_D', 'dis': 0.35}],
    
    # ì‹œì  4: íƒ€ê²Ÿì´ ë‹¤ì‹œ ìµœìƒìœ„
    [{'tid': 'song_X', 'dis': 0.08}, {'tid': 'song_E', 'dis': 0.19}, {'tid': 'song_F', 'dis': 0.31}],
    
    # ì‹œì  5: íƒ€ê²Ÿ ì—†ìŒ (ë‹¤ë¥¸ íŒ¨í„´)
    [{'tid': 'song_G', 'dis': 0.14}, {'tid': 'song_H', 'dis': 0.21}, {'tid': 'song_I', 'dis': 0.33}]
]

# í•™ìŠµ íƒ€ê²Ÿ: íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ìƒìœ„ê¶Œ ë“±ì¥ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
target_pattern = 1.0  # ìƒìœ„ê¶Œ ë“±ì¥ íŒ¨í„´

print("=== ìœ„ì¹˜ ê¸°ë°˜ ì‹œê³„ì—´ ì²­í¬ ë°ì´í„° ===")
for i, chunk in enumerate(chunks):
    songs_info = [f"pos{j+1}({item['dis']:.2f})" for j, item in enumerate(chunk)]
    has_target = any('song_X' in item['tid'] for item in chunk)
    target_pos = next((j+1 for j, item in enumerate(chunk) if 'song_X' in item['tid']), None)
    status = f"â† XëŠ” {target_pos}ìœ„" if has_target else ""
    print(f"ì‹œì  {i+1}: {songs_info} {status}")

print(f"\ní•™ìŠµ ëª©í‘œ: ì‹œê³„ì—´ íŒ¨í„´ìœ¼ë¡œ ìƒìœ„ê¶Œ ë“±ì¥ ê°€ëŠ¥ì„± ì˜ˆì¸¡")

# ì „ì²˜ë¦¬
chunk_features, chunk_adjs, chunk_sizes = preprocess_positional_chunks(chunks)

print("===========")
print(chunk_adjs)

exit(1)

# í…ì„œ ë³€í™˜
features_tensor = torch.FloatTensor(chunk_features)
adjs_tensor = torch.FloatTensor(chunk_adjs)
target_tensor = torch.FloatTensor([target_pattern])

# ëª¨ë¸ ìƒì„±
model = TimeSeriesPositionalRecommendation(
    node_features=3,
    hidden_features=32,
    time_features=16
)

# í•™ìŠµìš© íƒ€ê²Ÿ ìƒì„± (ê° ì²­í¬ì—ì„œ íƒ€ê²Ÿ ê³¡ì˜ ìœ„ì¹˜)
def create_training_targets(chunks, target_song='song_X'):
    """ê° ì²­í¬ì—ì„œ íƒ€ê²Ÿ ê³¡ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ìƒì„±"""
    targets = []
    for chunk in chunks:
        target_positions = []
        for i, item in enumerate(chunk):
            if target_song in item['tid']:
                # íƒ€ê²Ÿ ê³¡ì´ë©´ ë†’ì€ ì ìˆ˜ (ìƒìœ„ê¶Œì¼ìˆ˜ë¡ ë” ë†’ìŒ)
                position_score = 1.0 - (i / len(chunk))  # 0ìœ„=1.0, 1ìœ„=0.67, 2ìœ„=0.33
                target_positions.append(position_score)
            else:
                target_positions.append(0.1)  # ë¹„íƒ€ê²Ÿ ê³¡ì€ ë‚®ì€ ì ìˆ˜
        targets.append(target_positions)
    return targets

training_targets = create_training_targets(chunks, 'song_X')

# í•™ìŠµ
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

epochs = 1000
print(f"\n=== ìœ„ì¹˜ íŒ¨í„´ í•™ìŠµ ===")

for epoch in range(epochs):
    model.train()
    total_loss = 0
    
    # ê° ì²­í¬ë³„ë¡œ ë…¸ë“œ ì ìˆ˜ ì˜ˆì¸¡
    for chunk_idx, target_scores in enumerate(training_targets):
        if len(target_scores) > 0:  # ë¹ˆ ì²­í¬ê°€ ì•„ë‹ ë•Œë§Œ
            node_scores = model(features_tensor, adjs_tensor, chunk_sizes, predict_chunk_idx=chunk_idx)
            target_tensor = torch.FloatTensor(target_scores[:len(node_scores)])
            
            loss = criterion(node_scores, target_tensor)
            total_loss += loss
    
    avg_loss = total_loss / len(training_targets)
    
    optimizer.zero_grad()
    avg_loss.backward()
    optimizer.step()
    
    if (epoch + 1) % 200 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss.item():.6f}')

print(f"\n=== ìƒˆë¡œìš´ ë°ì´í„° í…ŒìŠ¤íŠ¸ ===")
# ì™„ì „íˆ ìƒˆë¡œìš´ ê³¡ë“¤ë¡œë§Œ êµ¬ì„±ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°
test_chunks = [
    [{'tid': 'new_song_1', 'dis': 0.09}, {'tid': 'new_song_2', 'dis': 0.18}, {'tid': 'new_song_3', 'dis': 0.27}],
    [{'tid': 'new_song_1', 'dis': 0.11}, {'tid': 'new_song_5', 'dis': 0.16}, {'tid': 'new_song_6', 'dis': 0.24}],
    [{'tid': 'new_song_1', 'dis': 0.13}, {'tid': 'new_song_8', 'dis': 0.29}, {'tid': 'new_song_9', 'dis': 0.35}],
]

print("í…ŒìŠ¤íŠ¸ ì²­í¬:")
for i, chunk in enumerate(test_chunks):
    songs_info = [f"{item['tid']}({item['dis']:.2f})" for item in chunk]
    print(f"ì‹œì  {i+1}: {songs_info}")

test_features, test_adjs, test_sizes = preprocess_positional_chunks(test_chunks)
test_features_tensor = torch.FloatTensor(test_features)
test_adjs_tensor = torch.FloatTensor(test_adjs)

model.eval()
with torch.no_grad():
    print(f"\n=== ê° ì²­í¬ë³„ ì¶”ì²œ ê²°ê³¼ ===")
    
    for chunk_idx, chunk in enumerate(test_chunks):
        # í•´ë‹¹ ì²­í¬ì˜ ê° ê³¡ì— ëŒ€í•œ ì¶”ì²œ ì ìˆ˜
        node_scores = model(test_features_tensor, test_adjs_tensor, test_sizes, predict_chunk_idx=chunk_idx)
        
        # ì ìˆ˜ì™€ ê³¡ ì •ë³´ ê²°í•©
        song_scores = []
        for i, (song_data, score) in enumerate(zip(chunk, node_scores)):
            song_scores.append({
                'song': song_data['tid'],
                'distance': song_data['dis'],
                'position': i + 1,
                'recommendation_score': score.item()
            })
        
        # ì¶”ì²œ ì ìˆ˜ë¡œ ì •ë ¬
        song_scores.sort(key=lambda x: x['recommendation_score'], reverse=True)
        
        print(f"\nì²­í¬ {chunk_idx + 1} ì¶”ì²œ ê²°ê³¼:")
        for i, song_info in enumerate(song_scores):
            print(f"  {i+1}ìœ„: {song_info['song']} "
                  f"(ì›ë˜ {song_info['position']}ìœ„, ê±°ë¦¬: {song_info['distance']:.2f}, "
                  f"ì¶”ì²œì ìˆ˜: {song_info['recommendation_score']:.4f})")
        
        best_recommendation = song_scores[0]
        print(f"  â†’ ìµœì¢… ì¶”ì²œ: {best_recommendation['song']} "
              f"(ì¶”ì²œì ìˆ˜: {best_recommendation['recommendation_score']:.4f})")

    # ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìµœê³  ì¶”ì²œê³¡ ì°¾ê¸°
    all_recommendations = []
    for chunk_idx, chunk in enumerate(test_chunks):
        node_scores = model(test_features_tensor, test_adjs_tensor, test_sizes, predict_chunk_idx=chunk_idx)
        for i, (song_data, score) in enumerate(zip(chunk, node_scores)):
            all_recommendations.append({
                'song': song_data['tid'],
                'chunk': chunk_idx + 1,
                'score': score.item()
            })
    
    # ì „ì²´ì—ì„œ ìµœê³  ì ìˆ˜
    all_recommendations.sort(key=lambda x: x['score'], reverse=True)
    
    print(f"\n=== ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìµœì¢… ì¶”ì²œ ===")
    print(f"ğŸµ ì¶”ì²œ ê³¡: {all_recommendations[0]['song']} "
          f"(ì²­í¬ {all_recommendations[0]['chunk']}, ì ìˆ˜: {all_recommendations[0]['score']:.4f})")
    
    print(f"\nìƒìœ„ 3ê°œ ì¶”ì²œ:")
    for i, rec in enumerate(all_recommendations[:3]):
        print(f"  {i+1}ìœ„: {rec['song']} (ì²­í¬ {rec['chunk']}, ì ìˆ˜: {rec['score']:.4f})")

print(f"\n=== ëª¨ë¸ íŠ¹ì§• ===")
print("âœ“ ê³¡ IDì— ì˜ì¡´í•˜ì§€ ì•ŠìŒ - ì™„ì „íˆ ìƒˆë¡œìš´ ê³¡ë„ ì²˜ë¦¬ ê°€ëŠ¥")
print("âœ“ ê±°ë¦¬, ìˆœìœ„, ìœ„ì¹˜ì  íŠ¹ì„±ë§Œìœ¼ë¡œ í•™ìŠµ")
print("âœ“ ê·¸ë˜í”„ êµ¬ì¡°ì™€ ì‹œê³„ì—´ íŒ¨í„´ì„ ë™ì‹œì— ê³ ë ¤")
print("âœ“ ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ ëª¨ë¥´ëŠ” ê³¡ë“¤ì—ë„ ì ìš© ê°€ëŠ¥")